#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import xgboost as xgb 
from xgboost import XGBClassifier
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, auc

# Change display options
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

modified_data = '/Documents/ZuckerAI/all_processed_7-25-21.csv'
df = pd.read_csv(modified_data)

### Normal Test/Train/Val split
strat_train_set, strat_temp_set = train_test_split(df, test_size=0.4, random_state=42)    
strat_val_set, strat_test_set = train_test_split(strat_temp_set, test_size=0.5, random_state=42)
    
# Make a Training Set to work with
Train = strat_train_set.copy()
Test = strat_test_set.copy()
Val = strat_val_set.copy()
#print(Train.head())

begin = 3
end = len(df.columns) - 4
result = len(df.columns)-1

X_train = Train.iloc[:, begin:end].values
y_train = Train.iloc[:, result].values
#print(X_train[0])

X_val = Val.iloc[:, begin:end].values
y_val = Val.iloc[:, result].values

X_test = Test.iloc[:, begin:end].values
y_test = Test.iloc[:, result].values


#import imblearn
#from imblearn.over_sampling import SMOTE 
#oversample = SMOTE()
#X, y = oversample.fit_resample(X_train, y_train)

##XGBoost
#from matplotlib import pyplot
#from numpy import loadtxt
#import bayes_opt
#from bayes_opt import BayesianOptimization
#from sklearn.metrics import mean_squared_error
#
##Converting the dataframe into XGBoostâ€™s Dmatrix object
#dtrain = xgb.DMatrix(X_train, y_train)
#
##Bayesian Optimization function for xgboost
##specify the parameters you want to tune as keyword arguments
#def bo_tune_xgb(max_depth, gamma, n_estimators ,learning_rate):
#     params = {'max_depth': int(max_depth),
#              'gamma': gamma,
#              'n_estimators': int(n_estimators),
#              'learning_rate':learning_rate,
#              'subsample': 0.8,
#              'eta': 0.1,
#              'eval_metric': 'rmse'}
#    #Cross validating with the specified parameters in 5 folds and 70 iterations
#     cv_result = xgb.cv(params, dtrain, num_boost_round=50, nfold=5)
#    #Return the negative RMSE
#     return -1.0 * cv_result['test-rmse-mean'].iloc[-1]
#
##Invoking the Bayesian Optimizer with the specified parameters to tune
#xgb_bo = BayesianOptimization(bo_tune_xgb, {'max_depth': (3, 10),
#                                             'gamma': (0, 1),
#                                             'learning_rate':(0,1),
#                                             'n_estimators':(100,120)
#                                            })
#
##performing Bayesian optimization for 5 iterations with 8 steps of random exploration with an #acquisition function of expected improvement
#xgb_bo.maximize(n_iter=5, init_points=8, acq='ei')
#
##Extracting the best parameters
#params = xgb_bo.max['params']
#print(params)
##
###Converting the max_depth and n_estimator values from float to int
##params['max_depth']= int(params['max_depth'])
##params['n_estimators']= int(params['n_estimators'])
     


###################
model = XGBClassifier(silent=False,
                      subsample= 1,
                      learning_rate=0.18578499169973484,
                      objective='binary:logistic', 
                      n_estimators=115,
                      max_depth=6, 
                      gamma=0.47618626251711826,
                      reg_lambda = 10,
                      reg_alpha = 15)

#### Fit with early stopping
#eval_set = [(X_val, y_val)]
#model.fit(X_train, y_train, early_stopping_rounds=100, eval_metric="logloss", eval_set=eval_set, verbose=True)

model.fit(X_train, y_train)

predictionsproba = model.predict_proba(X_val)
print(predictionsproba[2][1])

#Threshold
thresh = 0.35

#TTrainSet
y_pred1a=model.predict_proba(X_train)
y_pred1 = y_pred1a[:,1]
#convert into binary values
for i in range(len(y_pred1)):
    if y_pred1[i]>= thresh:       # setting threshold to .5
       y_pred1[i]=1
    else:  
       y_pred1[i]=0
       
cm1 = confusion_matrix(y_train, y_pred1)
accuracy1=accuracy_score(y_pred1,y_train)

print(cm1)
print("accuracy: ", accuracy1)
print("precision: ", precision_score(y_train, y_pred1))
print("recall: ", recall_score(y_train, y_pred1))
print("F1: ", f1_score(y_train, y_pred1))

#Validation
y_preda=model.predict_proba(X_val)
y_pred = y_preda[:,1]
#convert into binary values
for i in range(len(y_pred)):
    if y_pred[i]>= thresh:       # setting threshold to .5
       y_pred[i]=1
    else:  
       y_pred[i]=0
       
#Confusion matrix
cm = confusion_matrix(y_val, y_pred)
#Accuracy
accuracy=accuracy_score(y_pred,y_val)

print(cm)
print("accuracy: ", accuracy)
print("precision: ", precision_score(y_val, y_pred))
print("recall: ", recall_score(y_val, y_pred))
print("F1: ", f1_score(y_val, y_pred))

#TestSet
y_pred2a=model.predict_proba(X_test)
y_pred2 = y_pred2a[:,1]
#convert into binary values
for i in range(len(y_pred2)):
    if y_pred2[i]>= thresh:       # setting threshold to .5
       y_pred2[i]=1
    else:  
       y_pred2[i]=0
       
cm2 = confusion_matrix(y_test, y_pred2)
accuracy2=accuracy_score(y_pred2,y_test)

print(cm2)
print("accuracy: ", accuracy2)
print("precision: ", precision_score(y_test, y_pred2))
print("recall: ", recall_score(y_test, y_pred2))
print("F1: ", f1_score(y_test, y_pred2))

###PRECISION RECALL CURVES
#from sklearn.metrics import precision_recall_curve
#
#prediction_values = model.predict_proba(X_test)
#precisions, recalls, thresholds = precision_recall_curve(y_test, prediction_values[:,1])
#
#
#def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):
#    plt.plot(thresholds, precisions[:-1], "b--", label="Precision", linewidth=2)
#    plt.plot(thresholds, recalls[:-1], "g-", label="Recall", linewidth=2)
#    plt.xlabel("Threshold", fontsize=16)
#    plt.legend(loc="upper left", fontsize=16)
#    plt.ylim([0, 1])
#    
#plt.figure(figsize=(16, 8))
#plot_precision_recall_vs_threshold(precisions, recalls, thresholds)
#plt.show()
#
#
#def plot_precision_vs_recall(precisions, recalls):
#    plt.plot(recalls, precisions, "b-", linewidth=2)
#    plt.xlabel("Recall", fontsize=16)
#    plt.ylabel("Precision", fontsize=16)
#    plt.axis([0, 1, 0, 1])
#
#plt.figure(figsize=(16, 8))
#plot_precision_vs_recall(precisions, recalls)
#plt.show()
#
#from sklearn.metrics import roc_curve
#
#fpr, tpr, thresholds = roc_curve(y_test, prediction_values[:,1])
#print(auc(fpr, tpr))
#
#
#def plot_roc_curve(fpr, tpr, label=None):
#    plt.plot(fpr, tpr, linewidth=2, label=label)
#    plt.plot([0, 1], [0, 1], 'k--')
#    plt.axis([0, 1, 0, 1])
#    plt.xlabel('False Positive Rate', fontsize=16)
#    plt.ylabel('True Positive Rate', fontsize=16)
#
#plt.figure(figsize=(12, 12))
#plot_roc_curve(fpr, tpr)
#plt.show()

##Export via JobLib
#from sklearn.externals import joblib 
#import datetime
#from datetime import datetime, timedelta, date
#  
### Save the model as a pickle in a file 
#today = str(datetime.today()).split()[0]
#joblib.dump(model, f'M_XGBoost_{today}.pkl') 
#
#import sys 
#sys.exit()  
## Load the model from the file 
#knn_from_joblib = joblib.load('ZuckerAIModel.pkl')  
#  
## Use the loaded model to make predictions 
#knn_from_joblib.predict(X_test)
#

### Feature Importances
#model.get_booster().feature_names = ["Application Year", "Volunteer Hours", "Research Hours", "Publications", "Leadership Hours", "MCAT score", "Socionomic Indicator", "Military", "Pell Grant", "First Generation", "African American", "Latino", "Native American", "Citizen", "BCPM GPA", "Total GPA", "Institutional Action", "Parent Educational Status"]
#xgboost.plot_importance(model.get_booster())
#plt.title("Feature Importance")
#plt.show()
#y_predb = np.zeros(len(y_pred))
##Threshold Finder
#def use_cutoffs(y_pred, thresh):        #takes in a list of predictions and given threshold to output categories
#    for j in range(len(y_pred)):
#        if y_pred[j]>= thresh:       
#            y_predb[j]=1
#        else:  
#            y_predb[j]=0




